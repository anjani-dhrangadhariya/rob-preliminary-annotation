{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8fa19a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "id": "99f445a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir, path\n",
    "from os.path import isfile, join\n",
    "import json\n",
    "from lxml import html\n",
    "from bs4 import BeautifulSoup\n",
    "import string\n",
    "\n",
    "import requests,json\n",
    "from requests import get\n",
    "from requests.auth import HTTPBasicAuth, HTTPDigestAuth\n",
    "import urllib\n",
    "import itertools\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "\n",
    "import numpy\n",
    "\n",
    "# pytorch\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "535e823b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_whitespace(st):\n",
    "    for index, character in enumerate(st):\n",
    "        if character in string.whitespace:\n",
    "            yield index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "97a0649b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_combinations(l):\n",
    "    yield from itertools.product(l, l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e79db9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = 'RoB_preliminary_annotation'\n",
    "owner = 'anjDhr'\n",
    "users = ['rahel-caliesch', 'roger-annotation', 'martin-annotation', 'katia-giacomino', 'simone-annotation']\n",
    "all_user_combinations = list(itertools.combinations(users, 2)) \n",
    "all_user_combinations = get_combinations(users)\n",
    "all_user_combinations = list( all_user_combinations )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "653b6df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "exact_v1 = Stringent inter-annotator agreement\n",
    "overlapping_v1 = Relaxed inter-annotator agreement\n",
    "'''\n",
    "metrics = ['exact_v1', 'overlapping_v1'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1c34d0a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The response for query is:  <Response [200]>\n"
     ]
    }
   ],
   "source": [
    "# Get all the entities\n",
    "all_annotations_data = 'https://www.tagtog.net/-api/metrics/v0/search_stats?project=RoB_preliminary_annotation&owner=anjDhr&search=*'\n",
    "all_annotations_data_response = get(all_annotations_data, auth=('anjDhr', '9J@NiScMhUy9LbR'))\n",
    "print('The response for query is: ', all_annotations_data_response)\n",
    "all_annotations_data_response = json.loads(all_annotations_data_response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3834e784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the IAA metrics\n",
    "# IAA_hardcoded = 'https://www.tagtog.net/-api/metrics/v0/iaa?project=RoB_preliminary_annotation&owner=anjDhr&member1=rahel-caliesch&member2=roger-annotation&anntaskId=e_109&metric=exact_v1'\n",
    "IAA = 'https://www.tagtog.net/-api/metrics/v0/iaa?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "49468f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_annot = dict()\n",
    "user_agreement = dict() # what users have constant high agreement (relaxed agreement) between entities\n",
    "entity2label = dict()\n",
    "\n",
    "for eachEntry in all_annotations_data_response:\n",
    "    \n",
    "    if 'e_' in eachEntry:\n",
    "\n",
    "        entry_name =  all_annotations_data_response[eachEntry]['name']\n",
    "        entity_IAA = {}\n",
    "        \n",
    "        entity2label[eachEntry] = entry_name\n",
    "\n",
    "        for eachUserPair in all_user_combinations:\n",
    "\n",
    "            member1 = eachUserPair[0]\n",
    "            member2 = eachUserPair[1]\n",
    "\n",
    "            if member1 != member2:\n",
    "\n",
    "                params = (('project',project_name),('owner', owner), ('member1', member1), ('member2', member2), ('anntaskId', eachEntry), ('metric', metrics[1])) # metrics[1] = overlapping_v1\n",
    "                parameters = urllib.parse.urlencode(params)\n",
    "                entire_command = IAA + parameters\n",
    "                response = get(entire_command, auth=('anjDhr', '9J@NiScMhUy9LbR'))\n",
    "                my_json_data = json.loads(response.text)\n",
    "\n",
    "                if eachUserPair not in entity_IAA and tuple(reversed(eachUserPair)) not in entity_IAA:\n",
    "                    entity_IAA[eachUserPair] = my_json_data['f1']\n",
    "        global_annot[entry_name] = entity_IAA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "aa4d6ab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['e_178', 'e_109', 'e_205', 'e_138', 'e_121', 'e_199', 'e_116', 'e_127', 'e_160', 'e_156', 'e_171', 'e_195', 'e_167', 'e_132', 'e_184', 'e_142', 'e_164', 'e_152', 'e_163', 'e_174', 'e_188', 'e_210', 'e_190', 'e_166', 'e_208', 'e_115', 'e_133', 'e_214', 'e_122', 'e_177', 'e_111', 'e_137', 'e_147', 'e_146', 'e_158', 'e_155', 'e_126', 'e_203', 'e_113', 'e_194', 'e_187', 'e_143', 'e_151', 'e_198', 'e_183', 'e_140', 'e_110', 'e_204', 'e_169', 'e_119', 'e_216', 'e_211', 'e_200', 'e_215', 'e_125', 'e_202', 'e_136', 'e_159', 'e_173', 'e_154', 'e_176', 'e_114', 'e_207', 'e_193', 'e_162', 'e_123', 'e_165', 'e_213', 'e_186', 'e_118', 'e_157', 'e_170', 'e_130', 'e_197', 'e_182', 'e_124', 'e_180', 'e_107', 'e_129', 'e_135', 'e_148', 'e_150', 'e_179', 'e_168', 'e_144', 'e_131', 'e_201', 'e_189', 'e_212', 'e_217', 'e_161', 'e_175', 'e_206', 'e_149', 'e_196', 'e_153', 'e_120', 'e_172', 'e_192', 'e_141', 'e_117', 'e_181', 'e_128', 'e_209', 'e_112', 'e_145', 'e_191', 'e_139', 'e_185', 'e_134'])"
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity2label.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4df17a5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values(['4_1_Yes_Bad', '1_1_ProbablyYes_Good', '5_1_No_Bad', '2_4_Yes_Bad', '1_3_ProbablyNo_Good', '4_5_ProbablyYes_Bad', '1_2_ProbablyNo_Bad', '2_1_No_Information', '3_1_No_Bad', '2_7_ProbablyNo_Good', '3_3_ProbablyNo_Good', '4_4_No_Good', '3_2_No_Information', '2_2_No_Information', '4_2_ProbablyYes_Bad', '2_4_No_Information', '3_2_ProbablyYes_Good', '2_6_No_Information', '3_2_Yes_Good', '3_4_ProbablyYes_Bad', '4_3_Yes_Bad', '5_2_No_Good', '4_3_No_Good', '3_2_ProbablyNo_Bad', '5_2_Yes_Bad', '1_2_No_Bad', '2_3_Yes_Bad', '5_3_ProbablyYes_Bad', '1_3_No_Information', '3_4_No_Information', '1_1_ProbablyNo_Bad', '2_3_No_Information', '2_5_No_Information', '2_5_ProbablyNo_Bad', '3_1_Yes_Good', '2_7_No_Good', '2_1_ProbablyNo_Good', '5_1_Yes_Good', '1_2_Yes_Good', '4_4_ProbablyYes_Bad', '4_2_No_Information', '2_5_Yes_Good', '2_6_ProbablyNo_Bad', '4_5_Yes_Bad', '4_2_Yes_Bad', '2_4_No_Good', '1_1_No_Bad', '5_1_ProbablyYes_Good', '3_3_ProbablyYes_Bad', '1_3_ProbablyYes_Bad', '5_3_ProbablyNo_Good', '5_2_ProbablyNo_Good', '4_5_No_Good', '5_3_No_Good', '2_1_No_Good', '4_5_No_Information', '2_3_ProbablyNo_Good', '3_1_ProbablyYes_Good', '3_4_Yes_Bad', '2_7_ProbablyYes_Bad', '3_4_ProbablyNo_Good', '1_2_ProbablyYes_Good', '5_1_No_Information', '4_4_Yes_Bad', '3_1_No_Information', '2_1_Yes_Bad', '3_2_No_Bad', '5_3_Yes_Bad', '4_2_ProbablyNo_Good', '1_3_Yes_Bad', '2_7_No_Information', '3_3_No_Good', '2_2_No_Good', '4_4_No_Information', '4_1_No_Information', '2_1_ProbablyYes_Bad', '4_1_No_Good', '1_1_Yes_Good', '2_2_ProbablyYes_Bad', '2_3_No_Good', '2_6_Yes_Good', '2_6_No_Bad', '4_1_ProbablyYes_Bad', '3_3_Yes_Bad', '2_5_ProbablyYes_Good', '2_2_ProbablyNo_Good', '4_5_ProbablyNo_Good', '4_3_ProbablyYes_Bad', '5_2_No_Information', '5_3_No_Information', '3_1_ProbablyNo_Bad', '3_4_No_Good', '5_1_ProbablyNo_Bad', '2_6_ProbablyYes_Good', '4_4_ProbablyNo_Good', '2_7_Yes_Bad', '1_3_No_Good', '3_3_No_Information', '4_3_No_Information', '2_4_ProbablyNo_Good', '1_2_No_Information', '4_1_ProbablyNo_Good', '2_2_Yes_Bad', '5_2_ProbablyYes_Bad', '1_1_No_Information', '2_5_No_Bad', '4_3_ProbablyNo_Good', '2_4_ProbablyYes_Bad', '4_2_No_Good', '2_3_ProbablyYes_Bad'])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity2label.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "0c40a597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get plain texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "18501af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plain_text = '/home/anjani/rob-annotation/data/RoB_preliminary_annotation/plain.html/pool'\n",
    "member_annotations = '/home/anjani/rob-annotation/data/RoB_preliminary_annotation/ann.json/members/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6ddb79a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list down all the annotators\n",
    "\n",
    "projet_admin = ['anjDhr']\n",
    "\n",
    "member_dir = listdir( member_annotations )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "88fcc3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse plain text files for the trial annotation project\n",
    "\n",
    "plain_text_dict = dict()\n",
    "\n",
    "plain_texts = [f for f in listdir(plain_text) if isfile(join(plain_text, f))]\n",
    "\n",
    "for plaintext_file in plain_texts:\n",
    "    \n",
    "    plaintext_path = path.join(plain_text, plaintext_file)\n",
    "    \n",
    "    #with open(plaintext_path, \"r\") as f:\n",
    "    #    page = f.read()\n",
    "    page = open(plaintext_path, encoding=\"utf8\")  \n",
    "    \n",
    "    soup = BeautifulSoup(page)\n",
    "\n",
    "    #print(soup.head.title.text)\n",
    "    trial_doc_number = str(soup.head.title.text).replace('.pdf', '')\n",
    "    trial_doc_number = trial_doc_number.split('_')[-1]\n",
    "\n",
    "    text_list = soup.find_all(\"pre\")\n",
    "    \n",
    "    document_parts = {}\n",
    "    for l in text_list:\n",
    "        document_parts[ l.get('id') ] = l.text\n",
    "    \n",
    "    plain_text_dict[trial_doc_number] = document_parts\n",
    "    #for t in text_list:\n",
    "    #    print( t.get('id') )\n",
    "    #    print( t.text )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "be2e1a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List member annotation files\n",
    "\n",
    "member_annot_files = {}\n",
    "\n",
    "for m, member in enumerate(member_dir):\n",
    "    \n",
    "    if member not in projet_admin:\n",
    "        \n",
    "        member_annot_dir = member_annotations + str(member) + '/'\n",
    "        \n",
    "        member_annot_dir = path.join(member_annotations, member, 'pool')\n",
    "                \n",
    "        annotation_files = [path.join(member_annot_dir, f) for f in listdir(member_annot_dir) if isfile(join(member_annot_dir, f))]\n",
    "        \n",
    "        annotation_dict = {}\n",
    "        \n",
    "        # generate a dictionary of document_number : annotations parsed\n",
    "        for annotation_file in annotation_files:\n",
    "            \n",
    "            trial_doc_number = str(annotation_file).replace('.pdf.ann.json', '')\n",
    "            trial_doc_number = trial_doc_number.split('_')[-1]\n",
    "            \n",
    "            with open(annotation_file, 'r') as af:\n",
    "                data = json.load(af)\n",
    "                #print(data['entities'])\n",
    "                annotation_dict[trial_doc_number] = data['entities']\n",
    "        \n",
    "        \n",
    "        member_annot_files[member] = annotation_dict\n",
    "\n",
    "    #if m == 1:\n",
    "    #    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "3b616745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97f441485cba44be9cd8dd40003983ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c540016e41c34f1f873851d15f3deca3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/385 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "898834ee8f7f4860b07565054ed7523b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "9842cfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "tk = WhitespaceTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "a4ef7584",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatenAnnotations(annotator1, annotator2, annotations_all):\n",
    "    \n",
    "    annot1 = annotations_all[annotator1]\n",
    "    annot2 = annotations_all[annotator2]\n",
    "    annot1_flattened = []\n",
    "    annot2_flattened = []\n",
    "    \n",
    "    docs = list(annot1.keys())\n",
    "    \n",
    "    for doc in docs:\n",
    "        #print('Document number: ', doc)\n",
    "        doc_parts = list(annot1[doc].keys())\n",
    "        \n",
    "        for doc_part in doc_parts:\n",
    "            #print( doc_part )\n",
    "            if doc_part in annot1[doc] and doc_part in annot2[doc]:\n",
    "                annot1_flattened.extend( annot1[doc][doc_part]['labels'] )\n",
    "                annot2_flattened.extend( annot2[doc][doc_part]['labels'] )\n",
    "                \n",
    "            elif doc_part in annot1[doc] and doc_part not in annot2[doc]:\n",
    "                annot1_flattened.extend( annot1[doc][doc_part]['labels'] )\n",
    "                \n",
    "                temp2 = [[0]] * len( annot1[doc][doc_part]['labels'] )\n",
    "                annot2_flattened.extend( temp2 )\n",
    "                \n",
    "            elif doc_part not in annot1[doc] and doc_part in annot2[doc]:\n",
    "                temp1 = [[0]] * len( annot2[doc][doc_part]['labels'] )\n",
    "                annot1_flattened.extend( temp1 )\n",
    "                \n",
    "                annot2_flattened.extend( annot2[doc][doc_part]['labels'] )\n",
    "                \n",
    "    assert len( annot1_flattened ) == len( annot2_flattened )\n",
    "    \n",
    "    return annot1_flattened, annot2_flattened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "7180feea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseAnnotations(member_annotations):\n",
    "\n",
    "    annotation_docs = dict()\n",
    "\n",
    "    for k,v in member_annotations.items():\n",
    "\n",
    "        annotation_dict = dict()\n",
    "\n",
    "        for counter, a in enumerate(v):\n",
    "\n",
    "            document_part = a['part']\n",
    "            offset_start = a['offsets'][0]['start']\n",
    "            offset_end = offset_start + len(a['offsets'][0]['text'])\n",
    "            entity_text = a['offsets'][0]['text']\n",
    "            document = plain_text_dict[k][document_part]\n",
    "\n",
    "            document_entity_match = document[offset_start:offset_end]    \n",
    "            document_entity_match_label = a['classId']\n",
    "            assert len(entity_text) == len(document_entity_match)\n",
    "\n",
    "            match_label_list = len( entity_text ) * [document_entity_match_label]\n",
    "\n",
    "            document_char_labels = [0] * len(document)\n",
    "            document_char_labels[offset_start:offset_end] = match_label_list\n",
    "\n",
    "            if document_part not in annotation_dict:\n",
    "                annotation_dict[document_part] = [ document_char_labels ]\n",
    "            else:\n",
    "                annotation_dict[document_part].append( document_char_labels )\n",
    "\n",
    "        annotation_docs[k] = annotation_dict\n",
    "        \n",
    "    return annotation_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "ad76dd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def char2tokAnnot(char_annotations):\n",
    "    \n",
    "    token_annotations = {}\n",
    "    \n",
    "    for k_a, v_a in char_annotations.items():\n",
    "        #print(k_a) # document number\n",
    "        \n",
    "        token_annotations[k_a] = {}\n",
    "\n",
    "        for k_a_, v_a_ in v_a.items(): # convert char annot to tok annot\n",
    "            #print(k_a_) # document part\n",
    "\n",
    "            text =  plain_text_dict[k_a][k_a_]\n",
    "            white_space_spans = list(WhitespaceTokenizer().span_tokenize(plain_text_dict[k_a][k_a_]))\n",
    "            tokens = [ text[ ws[0] : ws[1] ] for ws in  white_space_spans ]\n",
    "            \n",
    "            for v_a_i in v_a_:\n",
    "            \n",
    "                labels = [ list( set(v_a_i[ ws[0] : ws[1] ]) ) for ws in  white_space_spans ]\n",
    "                #labels_clean = [ list(filter(lambda num: num != 0, l))[0] if len( l ) > 1 else l[0] for l in labels ]\n",
    "                labels_clean = [ list(filter(lambda num: num != 0, l)) if len( l ) > 1 else l for l in labels ]\n",
    "                #print('Clean labels: ' , labels_clean)\n",
    "            \n",
    "                assert len(v_a_i) == len(plain_text_dict[k_a][k_a_])                \n",
    "                assert len( tokens ) == len( labels )\n",
    "            \n",
    "                if k_a_ not in token_annotations[k_a]:\n",
    "                    token_annotations[k_a][k_a_] = {}\n",
    "                    token_annotations[k_a][k_a_]['tokens'] = tokens\n",
    "                    #token_annotations[k_a][k_a_]['labels'] = [ labels_clean ]\n",
    "                    token_annotations[k_a][k_a_]['labels'] = labels_clean\n",
    "                elif k_a_ in token_annotations[k_a]:\n",
    "                    old_labels = token_annotations[k_a][k_a_]['labels']\n",
    "                    new_labels = [ list(set(old_labels[n] + l)) for n, l in enumerate(labels_clean)]\n",
    "                    \n",
    "                    #new_labels = [ old_labels[n].append( l ) for n, l in enumerate(labels_clean) ]\n",
    "                    #print( new_labels )\n",
    "                    \n",
    "                    assert len( old_labels ) == len( new_labels )\n",
    "                    \n",
    "                    token_annotations[k_a][k_a_]['labels'] = new_labels\n",
    "            #break\n",
    "                \n",
    "    return token_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "500afa6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roger-annotation\n",
      "martin-annotation\n",
      "katia-giacomino\n"
     ]
    }
   ],
   "source": [
    "annotations = dict()\n",
    "\n",
    "for k,v in member_annot_files.items():\n",
    "\n",
    "    if len( list(v.keys()) ) == 10: # restricts it to those who completed annotations\n",
    "        print(k)\n",
    "        char_annotations = parseAnnotations(v)\n",
    "        tok_annotations = char2tokAnnot(char_annotations)\n",
    "        annotations[k] = tok_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "id": "a1033dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate IAA\n",
    "\n",
    "def calculate_exact_IAA(annotator1, annotator2, annotations_all):\n",
    "    \n",
    "    # Calculate different levels of inter-annotator agreement between the two annotators\n",
    "    \n",
    "    print( 'Calculating IAA between ', annotator1, ' and ', annotator2 )\n",
    "  \n",
    "    annot1_flat, annot2_flat = flatenAnnotations(annotator1, annotator2, annotations_all)\n",
    "    \n",
    "    # Completely flat lists\n",
    "    a1_flat = [x for xs in annot1_flat for x in xs]\n",
    "    a2_flat = [x for xs in annot2_flat for x in xs]\n",
    "    \n",
    "    entities = list( set( a1_flat + a2_flat ) )\n",
    "    entities.remove(0)\n",
    "        \n",
    "    # Get the annotator labels \n",
    "    annotator1_labels = dict.fromkeys( entities, len(annot1_flat) * [0] )\n",
    "    annotator2_labels = dict.fromkeys( entities, len(annot1_flat) * [0] )\n",
    "    \n",
    "    label1 = []\n",
    "    label2 = []\n",
    "    \n",
    "    for i, (a1, a2) in enumerate( zip(annot1_flat, annot2_flat) ):\n",
    "        \n",
    "        temp1_ent_dict = dict.fromkeys( entities, 0 )\n",
    "        temp2_ent_dict = dict.fromkeys( entities, 0 )\n",
    "                       \n",
    "        for a1_i in a1:\n",
    "            if a1_i != 0:\n",
    "                temp1_ent_dict[a1_i] = 1\n",
    "                \n",
    "        for a2_i in a2:\n",
    "            if a2_i != 0:\n",
    "                temp2_ent_dict[a2_i] = 1\n",
    "                \n",
    "        temp1_ent_list = []\n",
    "        temp2_ent_list = []\n",
    "        \n",
    "        for e in entities:\n",
    "            temp1_ent_list.append( temp1_ent_dict[e] )\n",
    "            temp2_ent_list.append( temp2_ent_dict[e] )\n",
    "            \n",
    "        #Append to the main list\n",
    "        if sum( temp1_ent_list ) > 0 or sum( temp2_ent_list ) > 0:\n",
    "            label1.append( temp1_ent_list )\n",
    "            label2.append( temp2_ent_list )\n",
    "        \n",
    "    f1_iaa = f1_score(label1, label2, average=None)\n",
    "    \n",
    "    for e, f1 in zip(entities, f1_iaa):\n",
    "        if f1 > 0:\n",
    "            print( entity2label[e], ' : ', f1*100 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "id": "01fe852b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating IAA between  roger-annotation  and  katia-giacomino\n",
      "1_2_ProbablyYes_Good  :  18.29652996845426\n",
      "1_3_No_Information  :  75.3694581280788\n",
      "3_1_ProbablyYes_Good  :  3.324099722991689\n",
      "1_3_ProbablyNo_Good  :  55.420412480169226\n",
      "2_6_Yes_Good  :  33.54037267080745\n",
      "4_1_ProbablyNo_Good  :  0.9508716323296353\n",
      "3_1_Yes_Good  :  98.06201550387598\n",
      "4_2_ProbablyNo_Good  :  1.8316308559351884\n",
      "1_1_Yes_Good  :  16.09195402298851\n",
      "4_1_No_Good  :  12.334801762114537\n",
      "1_1_ProbablyYes_Good  :  4.109589041095891\n",
      "1_2_No_Information  :  60.67415730337078\n"
     ]
    }
   ],
   "source": [
    "calculate_IAA_F1('roger-annotation', 'katia-giacomino', annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "id": "24389546",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_judgeless_IAA(annotator1, annotator2, annotations_all):\n",
    "    \n",
    "    # Calculate different levels of inter-annotator agreement between the two annotators\n",
    "    \n",
    "    print( 'Calculating IAA between ', annotator1, ' and ', annotator2 )\n",
    "  \n",
    "    annot1_flat, annot2_flat = flatenAnnotations(annotator1, annotator2, annotations_all)\n",
    "    \n",
    "    # Completely flat lists\n",
    "    a1_flat = [entity2label[x][0:3] if x != 0 else x for xs in annot1_flat for x in xs]\n",
    "    a2_flat = [entity2label[x][0:3] if x != 0 else x for xs in annot2_flat for x in xs]\n",
    "\n",
    "    entities = list( set( a1_flat + a2_flat ) )\n",
    "    entities.remove(0)\n",
    "\n",
    "    label1 = []\n",
    "    label2 = []\n",
    "    \n",
    "    for i, (a1, a2) in enumerate( zip(annot1_flat, annot2_flat) ):\n",
    "        \n",
    "        temp1_ent_dict = dict.fromkeys( entities, 0 )\n",
    "        temp2_ent_dict = dict.fromkeys( entities, 0 )\n",
    "        \n",
    "        for a1_i in a1:\n",
    "            if a1_i != 0:\n",
    "                relax1_ent = entity2label[a1_i][0:3]\n",
    "                if relax1_ent in temp1_ent_dict:\n",
    "                    temp1_ent_dict[relax1_ent] = 1\n",
    "                \n",
    "        for a2_i in a2:\n",
    "            if a2_i != 0:\n",
    "                relax2_ent = entity2label[a2_i][0:3]\n",
    "                if relax2_ent in temp2_ent_dict:\n",
    "                    temp2_ent_dict[relax2_ent] = 1\n",
    "                    \n",
    "        temp1_ent_list = []\n",
    "        temp2_ent_list = []\n",
    "        \n",
    "        for e in entities:\n",
    "            temp1_ent_list.append( temp1_ent_dict[e] )\n",
    "            temp2_ent_list.append( temp2_ent_dict[e] )\n",
    "            \n",
    "        #Append to the main list\n",
    "        if sum( temp1_ent_list ) > 0 or sum( temp2_ent_list ) > 0:\n",
    "            label1.append( temp1_ent_list )\n",
    "            label2.append( temp2_ent_list )\n",
    "            \n",
    "\n",
    "    f1_iaa = f1_score(label1, label2, average=None)\n",
    "    \n",
    "    for e, f1 in zip(entities, f1_iaa):\n",
    "        if f1 > 0:\n",
    "            print( e, ' : ', f1*100 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "id": "1918c39b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating IAA between  roger-annotation  and  katia-giacomino\n",
      "2_1  :  0.966183574879227\n",
      "3_2  :  1.3618677042801557\n",
      "5_3  :  0.11560693641618495\n",
      "4_2  :  1.7603249830737984\n",
      "5_2  :  23.83177570093458\n",
      "2_3  :  20.52980132450331\n",
      "2_6  :  75.23629489603026\n",
      "2_2  :  18.21036106750393\n",
      "1_2  :  66.04434072345391\n",
      "1_3  :  69.44444444444444\n",
      "3_1  :  45.75707154742096\n",
      "4_1  :  3.9627039627039626\n",
      "1_1  :  23.05475504322767\n",
      "4_3  :  7.569721115537847\n"
     ]
    }
   ],
   "source": [
    "calculate_judgeless_IAA('roger-annotation', 'katia-giacomino', annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "id": "d1b88e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating IAA between  roger-annotation  and  martin-annotation\n",
      "2_1  :  1.342281879194631\n",
      "2_7  :  6.521739130434782\n",
      "2_3  :  5.421686746987953\n",
      "2_6  :  68.85245901639344\n",
      "2_2  :  7.236842105263158\n",
      "1_2  :  50.289017341040456\n",
      "1_3  :  20.44801838024124\n",
      "3_1  :  23.57274401473297\n",
      "4_1  :  6.513872135102533\n",
      "1_1  :  24.440298507462686\n",
      "4_3  :  13.858267716535435\n"
     ]
    }
   ],
   "source": [
    "calculate_judgeless_IAA('roger-annotation', 'martin-annotation', annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "id": "5ca5690b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating IAA between  katia-giacomino  and  martin-annotation\n",
      "2_1  :  9.068010075566752\n",
      "3_2  :  3.263403263403264\n",
      "5_3  :  0.32\n",
      "2_6  :  63.89891696750903\n",
      "1_2  :  50.68702290076336\n",
      "1_3  :  31.536388140161726\n",
      "3_1  :  43.35664335664335\n",
      "4_1  :  25.60777957860616\n",
      "1_1  :  56.95006747638326\n",
      "3_3  :  16.3265306122449\n",
      "4_3  :  10.502283105022832\n"
     ]
    }
   ],
   "source": [
    "calculate_judgeless_IAA('katia-giacomino', 'martin-annotation', annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd15c02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e13f3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff96087",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "id": "ee33a0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate IAA\n",
    "\n",
    "def calculate_IAA(annotator1, annotator2, annotations_all):\n",
    "    \n",
    "    # Calculate different levels of inter-annotator agreement between the two annotators\n",
    "    \n",
    "    print( 'Calculating IAA between ', annotator1, ' and ', annotator2 )\n",
    "  \n",
    "    annot1_flat, annot2_flat = flatenAnnotations(annotator1, annotator2, annotations_all)\n",
    "    \n",
    "    # Completely flat lists\n",
    "    a1_flat = [x for xs in annot1_flat for x in xs]\n",
    "    a2_flat = [x for xs in annot2_flat for x in xs]\n",
    "    \n",
    "    IAA_Po = dict.fromkeys( list(entity2label.keys()) )\n",
    "\n",
    "    # Initialize valid annotated entities with 0\n",
    "    annotated_entities = list(set( a1_flat + a2_flat ))\n",
    "    for e in annotated_entities:\n",
    "        if e in IAA_Po:\n",
    "            IAA_Po[e] = 0\n",
    "    \n",
    "    for i, (a1, a2) in enumerate( zip( annot1_flat, annot2_flat ) ):\n",
    "        \n",
    "        if any(a1) != 0 and any(a2) != 0:\n",
    "            \n",
    "            unique = list(set(a1).intersection(a2))\n",
    "            for count in unique:\n",
    "                if count in IAA_Po:\n",
    "                    IAA_Po[count] = IAA_Po[count] + 1\n",
    "    \n",
    "    uniq = set(a1_flat + a2_flat)\n",
    "    E = 0  # expected agreement E (Pe)\n",
    "    for item in uniq:\n",
    "        cnt1 = a1_flat.count(item)\n",
    "        cnt2 = a2_flat.count(item)\n",
    "        count = ((cnt1 / len(a1_flat)) * (cnt2 / len(a2_flat)))\n",
    "        E += count\n",
    "        \n",
    "    IAA = dict.fromkeys( list(entity2label.keys()), 0 )\n",
    "    \n",
    "    for k,v in IAA_Po.items():\n",
    "        if v != 0 and v != None:\n",
    "            \n",
    "            iaa_agreement = round( (v - E) / (1 - E), 4 )\n",
    "            \n",
    "            print( k ,  iaa_agreement )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397221fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d8ebe0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fb5028",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1323f0cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "ff95dd25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24c9e5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
