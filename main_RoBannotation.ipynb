{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6c87899",
   "metadata": {},
   "source": [
    "# RoB annotations Inter Annotator Agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9aa4ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generic imports\n",
    "from os import listdir, path\n",
    "from os.path import isfile, join\n",
    "import json\n",
    "import string\n",
    "import itertools\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "\n",
    "# Connect to tagtog API\n",
    "from lxml import html\n",
    "from bs4 import BeautifulSoup\n",
    "from requests import get\n",
    "from requests.auth import HTTPBasicAuth, HTTPDigestAuth\n",
    "import urllib\n",
    "\n",
    "# Specific imports\n",
    "import numpy\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "from sklearn.metrics import f1_score, cohen_kappa_score\n",
    "\n",
    "\n",
    "# pytorch\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86950268",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_whitespace(st):\n",
    "    for index, character in enumerate(st):\n",
    "        if character in string.whitespace:\n",
    "            yield index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b99e9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_combinations(l):\n",
    "    yield from itertools.product(l, l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c71303ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = 'RoB_preliminary_annotation'\n",
    "owner = 'anjDhr'\n",
    "users = ['rahel-caliesch', 'roger-annotation', 'martin-annotation', 'katia-giacomino', 'simone-annotation']\n",
    "all_user_combinations = list(itertools.combinations(users, 2)) \n",
    "all_user_combinations = get_combinations(users)\n",
    "all_user_combinations = list( all_user_combinations )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "180bdec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "exact_v1 = Stringent inter-annotator agreement\n",
    "overlapping_v1 = Relaxed inter-annotator agreement\n",
    "'''\n",
    "metrics = ['exact_v1', 'overlapping_v1', 'documentlevel_v1'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01f7b74f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The response for query is:  <Response [200]>\n"
     ]
    }
   ],
   "source": [
    "# Get all the entities\n",
    "all_annotations_data = 'https://www.tagtog.com/-api/metrics/v0/search_stats?project=RoB_annotations_IAA&owner=anjDhr&search=*'\n",
    "all_annotations_data_response = get(all_annotations_data, auth=('anjDhr', '9J@NiScMhUy9LbR'))\n",
    "print('The response for query is: ', all_annotations_data_response)\n",
    "all_annotations_data_response = json.loads(all_annotations_data_response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca84e8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the IAA metrics\n",
    "# IAA_hardcoded = 'https://www.tagtog.net/-api/metrics/v0/iaa?project=RoB_preliminary_annotation&owner=anjDhr&member1=rahel-caliesch&member2=roger-annotation&anntaskId=e_109&metric=exact_v1'\n",
    "IAA = 'https://www.tagtog.com/-api/metrics/v0/iaa?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "733b5fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity2label = {}\n",
    "doc2label = {}\n",
    "\n",
    "for eachEntry in all_annotations_data_response:\n",
    "    \n",
    "    if 'e_' in eachEntry:\n",
    "\n",
    "        entry_name =  all_annotations_data_response[eachEntry]['name']       \n",
    "        entity2label[eachEntry] = entry_name\n",
    "        \n",
    "    if 'm_' in eachEntry:\n",
    "\n",
    "        entry_name =  all_annotations_data_response[eachEntry]['name']       \n",
    "        doc2label[eachEntry] = entry_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afd9d18",
   "metadata": {},
   "source": [
    "### Parse annotation project from local machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9bb986b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get plain texts\n",
    "plain_text = '/mnt/nas2/results/Results/systematicReview/RoB_annotation/IAA_annot/RoB_annotations_IAA_1/plain.html/pool'\n",
    "member_annotations = '/mnt/nas2/results/Results/systematicReview/RoB_annotation/IAA_annot/RoB_annotations_IAA_1/ann.json/members/'\n",
    "\n",
    "# list down all the annotators\n",
    "projet_admin = ['anjDhr']\n",
    "member_dir = listdir( member_annotations )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6153464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This project has annotations from: roger-annotation, katia-giacomino, rahel-caliesch\n"
     ]
    }
   ],
   "source": [
    "print('This project has annotations from:', ', '.join( member_dir ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6dded9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize tokenizer\n",
    "tk = WhitespaceTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd7e0125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse plain text files for the trial annotation project\n",
    "\n",
    "plain_text_dict = dict()\n",
    "plain_text_doclen = dict()\n",
    "\n",
    "plain_texts = [f for f in listdir(plain_text) if isfile(join(plain_text, f))]\n",
    "\n",
    "\n",
    "for plaintext_file in plain_texts:\n",
    "   \n",
    "    plaintext_path = path.join(plain_text, plaintext_file)\n",
    "\n",
    "    #with open(plaintext_path, \"r\") as f:\n",
    "    #    page = f.read()\n",
    "    page = open(plaintext_path, encoding=\"utf8\")  \n",
    "\n",
    "    soup = BeautifulSoup(page)\n",
    "\n",
    "    #print(soup.head.title.text)\n",
    "    trial_doc_number = str(soup.head.title.text).split('-')[-1].replace('.pdf', '')\n",
    "\n",
    "    text_list = soup.find_all(\"pre\")\n",
    "\n",
    "    document_parts = {}\n",
    "    doc_tok_len = 0\n",
    "    for l in text_list:\n",
    "\n",
    "        document_parts[ l.get('id') ] = l.text\n",
    "        token_text = tk.tokenize(l.text)\n",
    "        doc_tok_len = doc_tok_len + len(token_text)\n",
    "\n",
    "    plain_text_dict[trial_doc_number] = document_parts\n",
    "    plain_text_doclen[trial_doc_number] = doc_tok_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "3c5b8696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching annotations from  roger-annotation\n",
      "Fetching annotations from  katia-giacomino\n",
      "Fetching annotations from  rahel-caliesch\n"
     ]
    }
   ],
   "source": [
    "# List member annotation files\n",
    "\n",
    "doc_annot_count = 0\n",
    "document_annotations = dict()\n",
    "\n",
    "member_annot_files = {}\n",
    "\n",
    "for m, member in enumerate(member_dir):\n",
    "    \n",
    "    print('Fetching annotations from ', member)\n",
    "    \n",
    "    if member not in projet_admin:\n",
    "        \n",
    "        member_annot_dir = member_annotations + str(member) + '/'\n",
    "        \n",
    "        member_annot_dir = path.join(member_annotations, member, 'pool')\n",
    "                \n",
    "        annotation_files = [path.join(member_annot_dir, f) for f in listdir(member_annot_dir) if isfile(join(member_annot_dir, f))]\n",
    "        \n",
    "        annotation_dict = {}\n",
    "        \n",
    "        # generate a dictionary of document_number : annotations parsed\n",
    "        for annotation_file in annotation_files:\n",
    "            \n",
    "            #print( annotation_file )\n",
    "            \n",
    "            trial_doc_number = str(annotation_file).split('/')[-1].replace('.pdf.ann.json', '')\n",
    "            trial_doc_number = trial_doc_number.split('-')[-1]\n",
    "\n",
    "            with open(annotation_file, 'r') as af:\n",
    "                data = json.load(af)\n",
    "                                \n",
    "                if trial_doc_number not in document_annotations:\n",
    "                    document_annotations[trial_doc_number] =  [ data['metas'] ]\n",
    "                else:\n",
    "                    document_annotations[trial_doc_number].append( data['metas'] )\n",
    "                    \n",
    "                doc_annot_count = doc_annot_count + len(list(data['metas'].keys()))\n",
    "                \n",
    "                annotation_dict[trial_doc_number] = data['entities']\n",
    "        \n",
    "        \n",
    "        member_annot_files[member] = annotation_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec793372",
   "metadata": {},
   "outputs": [],
   "source": [
    "member2lastname = { 'roger-annotation': 'Hilfiker', 'katia-giacomino': 'Giacomino',  'rahel-caliesch': 'Caliesch'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ac58026",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseAnnotations(member_annotations):\n",
    "\n",
    "    annotation_docs = dict()\n",
    "    annotation_docs_text = dict()\n",
    "\n",
    "    for k,v in member_annotations.items():\n",
    "        \n",
    "        annotation_dict = dict()\n",
    "        annotation_text = []\n",
    "\n",
    "        for counter, a in enumerate(v):\n",
    "\n",
    "            document_part = a['part']\n",
    "            offset_start = a['offsets'][0]['start']\n",
    "            offset_end = offset_start + len(a['offsets'][0]['text'])\n",
    "            entity_text = a['offsets'][0]['text']\n",
    "            document = plain_text_dict[k][document_part]\n",
    "\n",
    "            document_entity_match = document[offset_start:offset_end]    \n",
    "            document_entity_match_label = a['classId']\n",
    "            assert len(entity_text) == len(document_entity_match)\n",
    "\n",
    "            match_label_list = len( entity_text ) * [document_entity_match_label]\n",
    "\n",
    "            document_char_labels = [0] * len(document)\n",
    "            document_char_labels[offset_start:offset_end] = match_label_list\n",
    "\n",
    "            annotation_text.append( ( entity_text, [entity2label[x] for x in list(set(document_char_labels)) if x in entity2label ] ) )\n",
    "\n",
    "            if document_part not in annotation_dict:\n",
    "                annotation_dict[document_part] = [ document_char_labels ]\n",
    "            else:\n",
    "                annotation_dict[document_part].append( document_char_labels )\n",
    "\n",
    "        annotation_docs[k] = annotation_dict\n",
    "        annotation_docs_text[k] = annotation_text\n",
    "        \n",
    "    return annotation_docs, annotation_docs_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b7ae5715",
   "metadata": {},
   "outputs": [],
   "source": [
    "def char2tokAnnot(char_annotations):\n",
    "    \n",
    "    token_annotations = {}\n",
    "    \n",
    "    for k_a, v_a in char_annotations.items():\n",
    "        #print(k_a) # document number\n",
    "        \n",
    "        token_annotations[k_a] = {}\n",
    "\n",
    "        for k_a_, v_a_ in v_a.items(): # convert char annot to tok annot\n",
    "            #print(k_a_) # document part\n",
    "\n",
    "            text =  plain_text_dict[k_a][k_a_]\n",
    "            white_space_spans = list(WhitespaceTokenizer().span_tokenize(plain_text_dict[k_a][k_a_]))\n",
    "            tokens = [ text[ ws[0] : ws[1] ] for ws in  white_space_spans ]\n",
    "            \n",
    "            for v_a_i in v_a_:\n",
    "            \n",
    "                labels = [ list( set(v_a_i[ ws[0] : ws[1] ]) ) for ws in  white_space_spans ]\n",
    "                #labels_clean = [ list(filter(lambda num: num != 0, l))[0] if len( l ) > 1 else l[0] for l in labels ]\n",
    "                labels_clean = [ list(filter(lambda num: num != 0, l)) if len( l ) > 1 else l for l in labels ]\n",
    "                #print('Clean labels: ' , labels_clean)\n",
    "            \n",
    "                assert len(v_a_i) == len(plain_text_dict[k_a][k_a_])                \n",
    "                assert len( tokens ) == len( labels )\n",
    "            \n",
    "                if k_a_ not in token_annotations[k_a]:\n",
    "                    token_annotations[k_a][k_a_] = {}\n",
    "                    token_annotations[k_a][k_a_]['tokens'] = tokens\n",
    "                    token_annotations[k_a][k_a_]['labels'] = labels_clean\n",
    "                                        \n",
    "                elif k_a_ in token_annotations[k_a]:\n",
    "                    old_labels = token_annotations[k_a][k_a_]['labels']\n",
    "                    new_labels = [ list(set(old_labels[n] + l)) for n, l in enumerate(labels_clean)]\n",
    "                    \n",
    "                    #new_labels = [ old_labels[n].append( l ) for n, l in enumerate(labels_clean) ]\n",
    "                    #print( new_labels )\n",
    "                    \n",
    "                    assert len( old_labels ) == len( new_labels )\n",
    "                    \n",
    "                    token_annotations[k_a][k_a_]['labels'] = new_labels\n",
    "            #break\n",
    "                \n",
    "    return token_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1dcc2517",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = dict()\n",
    "annotation_text = dict()\n",
    "\n",
    "for k,v in member_annot_files.items():\n",
    "\n",
    "    #if len( list(v.keys()) ) >= 8: # restricts it to those who completed annotations\n",
    "    #    print(k)\n",
    "    char_annotations, annot_text = parseAnnotations(v)\n",
    "    tok_annotations = char2tokAnnot(char_annotations)\n",
    "    annotations[k] = tok_annotations\n",
    "    annotation_text[k] = annot_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3da77f75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['roger-annotation', 'katia-giacomino', 'rahel-caliesch'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b8ce8bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roger-annotation\n",
      "dict_keys(['s2v1', 's3v1'])\n",
      "katia-giacomino\n",
      "dict_keys(['s2v1', 's3v1'])\n",
      "rahel-caliesch\n",
      "dict_keys(['s5v1', 's13v1'])\n"
     ]
    }
   ],
   "source": [
    "for k,v in annotations.items():\n",
    "    \n",
    "    print(k)\n",
    "    \n",
    "    for k_, v_ in v.items():\n",
    "        \n",
    "        print(v_.keys())\n",
    "        \n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7975f1",
   "metadata": {},
   "source": [
    "## Calculate Inter Annotator Agreement (Exact) <br>\n",
    "Inter Annotator Agreement or IAA for Named Entity Recognition is usually calculated as F1-score rather than Cohen's kappa or Fleiss' kappa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e9433cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatenAnnotations(annotator1, annotator2, annotations_all):\n",
    "      \n",
    "    annot1 = annotations_all[annotator1]\n",
    "    annot2 = annotations_all[annotator2]\n",
    "    annot1_flattened = []\n",
    "    annot2_flattened = []\n",
    "    \n",
    "    if len( list(annot1.keys()) ) > len( list(annot2.keys()) ):\n",
    "        docs = list(annot2.keys())\n",
    "    else:\n",
    "        docs = list(annot1.keys())\n",
    "    \n",
    "    #print( annot1.keys() )\n",
    "    \n",
    "    for doc in docs:\n",
    "        #print('Document number: ', doc)\n",
    "        \n",
    "        if member2lastname[annotator1] in doc and member2lastname[annotator2] in doc:\n",
    "            \n",
    "            doc_parts = list(annot1[doc].keys())\n",
    "\n",
    "            for doc_part in doc_parts:\n",
    "                if doc_part in annot1[doc] and doc_part in annot2[doc]:\n",
    "                    annot1_flattened.extend( annot1[doc][doc_part]['labels'] )\n",
    "                    annot2_flattened.extend( annot2[doc][doc_part]['labels'] )\n",
    "\n",
    "                elif doc_part in annot1[doc] and doc_part not in annot2[doc]:\n",
    "                    annot1_flattened.extend( annot1[doc][doc_part]['labels'] )\n",
    "\n",
    "                    temp2 = [[0]] * len( annot1[doc][doc_part]['labels'] )\n",
    "                    annot2_flattened.extend( temp2 )\n",
    "\n",
    "                elif doc_part not in annot1[doc] and doc_part in annot2[doc]:\n",
    "                    temp1 = [[0]] * len( annot2[doc][doc_part]['labels'] )\n",
    "                    annot1_flattened.extend( temp1 )\n",
    "\n",
    "                    annot2_flattened.extend( annot2[doc][doc_part]['labels'] )\n",
    "\n",
    "    \n",
    "    assert len( annot1_flattened ) == len( annot2_flattened )\n",
    "    \n",
    "    return annot1_flattened, annot2_flattened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "86b7685f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate exact IAA\n",
    "\n",
    "# agreement_type = {'exact', 'judgeless'}\n",
    "\n",
    "def calculate_exact_IAA(annotator1, annotator2, annotations_all):\n",
    "    \n",
    "    # Calculate different levels of inter-annotator agreement between the two annotators\n",
    "    \n",
    "    print( 'Calculating IAA between ', annotator1, ' and ', annotator2 )\n",
    "  \n",
    "    annot1_flat, annot2_flat = flatenAnnotations(annotator1, annotator2, annotations_all)\n",
    "    \n",
    "    assert len(annot1_flat) == len(annot2_flat)\n",
    "    \n",
    "    a1 = []\n",
    "    a2 = []\n",
    "    \n",
    "    for i, j in zip(annot1_flat, annot2_flat):\n",
    "        \n",
    "        out_of_span_condition = (len(i) == 1 and len(j) == 1 and i[0] == 0 and j[0] == 0)\n",
    "        \n",
    "        if out_of_span_condition:\n",
    "            continue\n",
    "        else:\n",
    "            a1.append( i )\n",
    "            a2.append( j )\n",
    "            \n",
    "     \n",
    "    for k, v in entity2label.items():\n",
    "        \n",
    "        p1 = []\n",
    "        p2 = []\n",
    "        \n",
    "        for i, j in zip(a1, a2):\n",
    "            \n",
    "            if k in i or k in j:\n",
    "\n",
    "                if k in i:\n",
    "                    p1.append( 1 )\n",
    "                else:\n",
    "                    p1.append( 0 )\n",
    "\n",
    "                if k in j:\n",
    "                    p2.append( 1 )\n",
    "                else:\n",
    "                    p2.append( 0 )\n",
    "        \n",
    "        k_f1 = f1_score(p1, p2, average=None)\n",
    "        \n",
    "        if len(k_f1) > 1:\n",
    "            print( 'The agreement for entity ', entity2label[k], ' is ', k_f1[1] )\n",
    "        else:\n",
    "            print( 'NO AGREEMENT for entity ', entity2label[k], ' is ', k_f1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a73fe03e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating IAA between  roger-annotation  and  katia-giacomino\n",
      "The agreement for entity  1_3_No_Information  is  0.0\n",
      "NO AGREEMENT for entity  2_1_No_Good  is  []\n",
      "The agreement for entity  1_1_No_Information  is  0.0\n",
      "The agreement for entity  1_1_No_Bad  is  0.0\n",
      "The agreement for entity  1_3_No_Good  is  0.43270476464661006\n",
      "The agreement for entity  1_2_No_Bad  is  0.0\n",
      "NO AGREEMENT for entity  1_2_No_Information  is  []\n",
      "The agreement for entity  1_3_Yes_Bad  is  0.0\n",
      "The agreement for entity  1_2_Yes_Good  is  0.41681901279707495\n",
      "The agreement for entity  1_1_Yes_Good  is  0.5675213675213674\n"
     ]
    }
   ],
   "source": [
    "calculate_exact_IAA('roger-annotation', 'katia-giacomino', annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2dfd4fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating IAA between  roger-annotation  and  rahel-caliesch\n",
      "NO AGREEMENT for entity  1_3_No_Information  is  []\n",
      "NO AGREEMENT for entity  2_1_No_Good  is  []\n",
      "NO AGREEMENT for entity  1_1_No_Information  is  []\n",
      "NO AGREEMENT for entity  1_1_No_Bad  is  []\n",
      "NO AGREEMENT for entity  1_3_No_Good  is  [1.]\n",
      "The agreement for entity  1_2_No_Bad  is  0.0\n",
      "NO AGREEMENT for entity  1_2_No_Information  is  []\n",
      "NO AGREEMENT for entity  1_3_Yes_Bad  is  []\n",
      "The agreement for entity  1_2_Yes_Good  is  0.0\n",
      "The agreement for entity  1_1_Yes_Good  is  0.34375000000000006\n"
     ]
    }
   ],
   "source": [
    "calculate_exact_IAA('roger-annotation', 'rahel-caliesch', annotations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1becc5dc",
   "metadata": {},
   "source": [
    "## Calculate Inter Annotator Agreement (Judgementless) <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "eb2b40eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define RoB signalling questions\n",
    "\n",
    "RoB_signalling_list = ['1_1', '1_2', '1_3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "31f42b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate exact IAA\n",
    "\n",
    "# agreement_type = {'exact', 'judgeless'}\n",
    "\n",
    "def calculate_judgeless_IAA(annotator1, annotator2, annotations_all, rob:str):\n",
    "    \n",
    "    # Calculate different levels of inter-annotator agreement between the two annotators\n",
    "    \n",
    "    print( 'Calculating IAA between ', annotator1, ' and ', annotator2 )\n",
    "  \n",
    "    annot1_flat, annot2_flat = flatenAnnotations(annotator1, annotator2, annotations_all)\n",
    "    \n",
    "    assert len(annot1_flat) == len(annot2_flat)\n",
    "    \n",
    "    a1 = []\n",
    "    a2 = []\n",
    "    \n",
    "    for i, j in zip(annot1_flat, annot2_flat):\n",
    "        \n",
    "        out_of_span_condition = (len(i) == 1 and len(j) == 1 and i[0] == 0 and j[0] == 0)\n",
    "        \n",
    "        if out_of_span_condition:\n",
    "            continue\n",
    "        else:\n",
    "            a1.append( i )\n",
    "            a2.append( j )\n",
    "            \n",
    "     \n",
    "    for k in [i for i in RoB_signalling_list if i.startswith(rob)]:\n",
    "        \n",
    "        print('Calculating IAA for risk domain: ', k )\n",
    "        \n",
    "        p1 = []\n",
    "        p2 = []\n",
    "        \n",
    "        for i, j in zip(a1, a2):\n",
    "                      \n",
    "            i_mod = [ str(entity2label[ele])[0:3] if ele in entity2label else 0 for ele in i ]\n",
    "            j_mod = [ str(entity2label[ele])[0:3] if ele in entity2label else 0 for ele in j ] \n",
    "            \n",
    "            if k in i_mod or k in j_mod:\n",
    "\n",
    "                if k in i_mod:\n",
    "                    p1.append( 1 )\n",
    "                else:\n",
    "                    p1.append( 0 )\n",
    "\n",
    "                if k in j_mod:\n",
    "                    p2.append( 1 )\n",
    "                else:\n",
    "                    p2.append( 0 )\n",
    "        \n",
    "        k_f1 = f1_score(p1, p2, average=None)\n",
    "        \n",
    "        if len(k_f1) > 1:\n",
    "            print( 'The agreement for signalling question ', k, ' is ', k_f1[1] )\n",
    "        else:\n",
    "            print( 'NO AGREEMENT for signalling question ', k, ' is ', k_f1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a01adeec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating IAA between  roger-annotation  and  katia-giacomino\n",
      "Calculating IAA for risk domain:  1_1\n",
      "The agreement for signalling question  1_1  is  0.6698412698412698\n",
      "Calculating IAA for risk domain:  1_2\n",
      "The agreement for signalling question  1_2  is  0.6620498614958449\n",
      "Calculating IAA for risk domain:  1_3\n",
      "The agreement for signalling question  1_3  is  0.9364071505323827\n"
     ]
    }
   ],
   "source": [
    "calculate_judgeless_IAA('roger-annotation', 'katia-giacomino', annotations, '1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d21c0817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating IAA between  roger-annotation  and  rahel-caliesch\n",
      "Calculating IAA for risk domain:  1_1\n",
      "The agreement for signalling question  1_1  is  0.34375000000000006\n",
      "Calculating IAA for risk domain:  1_2\n",
      "The agreement for signalling question  1_2  is  0.0\n",
      "Calculating IAA for risk domain:  1_3\n",
      "NO AGREEMENT for signalling question  1_3  is  [1.]\n"
     ]
    }
   ],
   "source": [
    "calculate_judgeless_IAA('roger-annotation', 'rahel-caliesch', annotations, '1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3dd833",
   "metadata": {},
   "source": [
    "## Calculate Inter Annotator Agreement (document level) <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "4cf9d42f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'m_13': 'RoB4',\n",
       " 'm_10': 'RoB1',\n",
       " 'm_14': 'RoB5',\n",
       " 'm_9': 'overall_RoB',\n",
       " 'm_11': 'RoB2',\n",
       " 'm_12': 'RoB3'}"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "60a847b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "docannot2label = {'Some-concerns': 0, 'Low-risk': 1, 'High-risk': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "f0d40dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_doc_IAA(annotator1, annotator2, annotations_all, b_d:str):\n",
    "    \n",
    "    # Calculate different levels of inter-annotator agreement between the two annotators\n",
    "    \n",
    "    print( 'Calculating document IAA between ', annotator1, ' and ', annotator2 )\n",
    "    \n",
    "    doc_annot_1 = []\n",
    "    doc_annot_2 = []\n",
    "                \n",
    "\n",
    "    for k, v in annotations_all.items():\n",
    "\n",
    "        #print( k )\n",
    "\n",
    "        if member2lastname[annotator1] in k and member2lastname[annotator2] in k and len(v) == 2 and b_d in v[0] and b_d in v[1]:\n",
    "            \n",
    "            a1 = v[0][b_d]['value']\n",
    "            a2 = v[1][b_d]['value']\n",
    "                        \n",
    "            doc_annot_1.append(docannot2label[a1])\n",
    "            doc_annot_2.append(docannot2label[a2])\n",
    "            \n",
    "            \n",
    "    kappa_b_d = cohen_kappa_score(doc_annot_1, doc_annot_2, labels=None, weights=None)\n",
    "    \n",
    "    print( doc_annot_1 )\n",
    "    print( doc_annot_2 )\n",
    "    \n",
    "    print( kappa_b_d )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "0a5355b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating document IAA between  roger-annotation  and  katia-giacomino\n",
      "[0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0]\n",
      "[2, 1, 1, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1]\n",
      "0.07284768211920534\n"
     ]
    }
   ],
   "source": [
    "calculate_doc_IAA('roger-annotation', 'katia-giacomino', document_annotations, 'm_10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "714cf44e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating document IAA between  roger-annotation  and  rahel-caliesch\n",
      "[{'m_10': {'value': 'Low-risk', 'confidence': {'state': 'pre-added', 'who': ['user:roger-annotation'], 'prob': 1}}}, {'m_10': {'value': 'Low-risk', 'confidence': {'state': 'pre-added', 'who': ['user:rahel-caliesch'], 'prob': 1}}}]\n",
      "[1]\n",
      "[1]\n",
      "nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anjani/pico/lib/python3.6/site-packages/sklearn/metrics/_classification.py:641: RuntimeWarning: invalid value encountered in true_divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n"
     ]
    }
   ],
   "source": [
    "calculate_doc_IAA('roger-annotation', 'rahel-caliesch', document_annotations, 'm_10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb0a227",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
